{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### © Habibi Group, Fall 2024\n",
    "This the third model for the project. It uses a custom build vectorizer to make sparse vectors for each sentence and then uses cosine distance (dot product) as the nearess measure. The model is trained on the training data and then tested on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*THIS IS THE COMBINED DATA FLAVOR 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1gGiWDmLopXO"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset for the *Naive Bayes* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2df_TT_IopXR",
    "outputId": "e85253b3-11a2-443a-8fb6-e7f182853642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>local_id</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://urdu.arynews.tv/car-sales-in-pakistan/</td>\n",
       "      <td>پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ</td>\n",
       "      <td>ملکی آٹو سیکٹر سے زبردست خبر آگئی۔ پاکستان می...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://urdu.arynews.tv/gold-rates-in-pakistan-3/</td>\n",
       "      <td>پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟</td>\n",
       "      <td>کراچی: کاروباری ہفتے کے پہلے روز سونے کی قیمت ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://urdu.arynews.tv/cotton-production-cott...</td>\n",
       "      <td>امریکا سے معیاری روئی کی درآمد بڑھ گئی</td>\n",
       "      <td>کراچی: پاکستان میں کپاس کی پیداوار میں کمی کے ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>https://urdu.arynews.tv/psx-today-11-nov/</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج نے ایک اور سنگ میل عبور...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>https://urdu.arynews.tv/ghee-and-cooking-oil-p...</td>\n",
       "      <td>عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...</td>\n",
       "      <td>لاہور : گھی اور کوکنگ آئل کی قیمتوں میں ایک با...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  local_id                                               link  \\\n",
       "0   1         1     https://urdu.arynews.tv/car-sales-in-pakistan/   \n",
       "1   2         2  https://urdu.arynews.tv/gold-rates-in-pakistan-3/   \n",
       "2   3         5  https://urdu.arynews.tv/cotton-production-cott...   \n",
       "3   4         3          https://urdu.arynews.tv/psx-today-11-nov/   \n",
       "4   5         4  https://urdu.arynews.tv/ghee-and-cooking-oil-p...   \n",
       "\n",
       "                                               title  \\\n",
       "0          پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ   \n",
       "1         پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟   \n",
       "2             امریکا سے معیاری روئی کی درآمد بڑھ گئی   \n",
       "3           پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم   \n",
       "4  عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...   \n",
       "\n",
       "                                             content gold_label  \n",
       "0  ملکی آٹو سیکٹر سے زبردست خبر آگئی۔ پاکستان می...   Business  \n",
       "1  کراچی: کاروباری ہفتے کے پہلے روز سونے کی قیمت ...   Business  \n",
       "2  کراچی: پاکستان میں کپاس کی پیداوار میں کمی کے ...   Business  \n",
       "3  پاکستان اسٹاک ایکسچینج نے ایک اور سنگ میل عبور...   Business  \n",
       "4  لاہور : گھی اور کوکنگ آئل کی قیمتوں میں ایک با...   Business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv('../combined_data/dataset.csv')\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "1jbQpNEhopXS",
    "outputId": "2d9b338a-ed39-4cf8-dcd5-526df67bc419"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>local_id</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://urdu.arynews.tv/car-sales-in-pakistan/</td>\n",
       "      <td>پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ</td>\n",
       "      <td>ملک آٹ سیکٹر س زبردست خبر آگئی۔ پاکستان گاڑی ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://urdu.arynews.tv/gold-rates-in-pakistan-3/</td>\n",
       "      <td>پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟</td>\n",
       "      <td>کراچ کاروبار ہفت پہل روز سون قیمت رجحان رہا۔ پ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://urdu.arynews.tv/cotton-production-cott...</td>\n",
       "      <td>امریکا سے معیاری روئی کی درآمد بڑھ گئی</td>\n",
       "      <td>کراچ پاکستان کپاس پیداوار باعث اسپننگ مل س معی...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>https://urdu.arynews.tv/psx-today-11-nov/</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم</td>\n",
       "      <td>پاکستان اسٹاک ایکسچینج ن میل عبور لیا۔ کاروبار...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>https://urdu.arynews.tv/ghee-and-cooking-oil-p...</td>\n",
       "      <td>عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...</td>\n",
       "      <td>لاہور کوکنگ آئل قیمت اضاف ہوا، قمیت س تجاوز کر...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  local_id                                               link  \\\n",
       "0   1         1     https://urdu.arynews.tv/car-sales-in-pakistan/   \n",
       "1   2         2  https://urdu.arynews.tv/gold-rates-in-pakistan-3/   \n",
       "2   3         5  https://urdu.arynews.tv/cotton-production-cott...   \n",
       "3   4         3          https://urdu.arynews.tv/psx-today-11-nov/   \n",
       "4   5         4  https://urdu.arynews.tv/ghee-and-cooking-oil-p...   \n",
       "\n",
       "                                               title  \\\n",
       "0          پاکستان میں گاڑیوں کی فروخت میں بڑا اضافہ   \n",
       "1         پاکستان میں سونے کی قیمت آج کتنی کم ہوئی؟   \n",
       "2             امریکا سے معیاری روئی کی درآمد بڑھ گئی   \n",
       "3           پاکستان اسٹاک ایکسچینج میں نئی تاریخ رقم   \n",
       "4  عوام کے لیے نئی مشکل : گھی اور کوکنگ آئل کی قی...   \n",
       "\n",
       "                                             content gold_label  \n",
       "0  ملک آٹ سیکٹر س زبردست خبر آگئی۔ پاکستان گاڑی ...   Business  \n",
       "1  کراچ کاروبار ہفت پہل روز سون قیمت رجحان رہا۔ پ...   Business  \n",
       "2  کراچ پاکستان کپاس پیداوار باعث اسپننگ مل س معی...   Business  \n",
       "3  پاکستان اسٹاک ایکسچینج ن میل عبور لیا۔ کاروبار...   Business  \n",
       "4  لاہور کوکنگ آئل قیمت اضاف ہوا، قمیت س تجاوز کر...   Business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the data\n",
    "# Add this function to perform stemming\n",
    "def simple_urdu_stemmer(word):\n",
    "    suffixes = ['یں', 'اں', 'وں', 'یں', 'ہاں', 'ی', 'ے', 'و', 'ہ']\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "# Loading Urdu stopwords from the json file\n",
    "with open('../data/kaggle_stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    urdu_stopwords = set(json.load(file).keys())\n",
    "\n",
    "#Loading Shanzae Stopwords\n",
    "with open('../data/shanzae/stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    shanzae_stopwords = set(json.load(file).keys())\n",
    "\n",
    "#Loading Yamsheen Stopwords\n",
    "with open('../data/yamsheen/stopwords.json', 'r', encoding='utf-8') as file:\n",
    "    yamsheen_stopwords = set(json.load(file).keys())\n",
    "\n",
    "# Function to clean our Urdu sentences\n",
    "def clean_content(text, stopwords):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    text = ' '.join(word for word in text.split() if word not in shanzae_stopwords)\n",
    "    text = ' '.join(word for word in text.split() if word not in yamsheen_stopwords)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(simple_urdu_stemmer(word) for word in text.split())\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: clean_content(x, urdu_stopwords))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Multi-Label Classification Neural Network\n",
    "class MultiLabelNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.layers_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "        \n",
    "        for i in range(len(self.layers_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(self.layers_sizes[i], self.layers_sizes[i+1]) * np.sqrt(2./self.layers_sizes[i]))\n",
    "            self.biases.append(np.zeros((1, self.layers_sizes[i+1])))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            net = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.activations.append(self.sigmoid(net))\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward_propagation(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        delta = output - y\n",
    "        \n",
    "        dWeights = []\n",
    "        dBiases = []\n",
    "        \n",
    "        for i in range(len(self.weights) - 1, -1, -1):\n",
    "            dW = np.dot(self.activations[i].T, delta) / m\n",
    "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            \n",
    "            if i > 0:\n",
    "                delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            \n",
    "            dWeights.insert(0, dW)\n",
    "            dBiases.insert(0, db)\n",
    "        \n",
    "        return dWeights, dBiases\n",
    "\n",
    "    def fit(self, X, y, epochs=100, batch_size=32, verbose=True):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Mini-batch gradient descent\n",
    "            indices = np.random.permutation(m)\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "            \n",
    "            for i in range(0, m, batch_size):\n",
    "                batch_X = X[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                \n",
    "                output = self.forward_propagation(batch_X)\n",
    "                dWeights, dBiases = self.backward_propagation(batch_X, batch_y, output)\n",
    "                \n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= self.learning_rate * dWeights[j]\n",
    "                    self.biases[j] -= self.learning_rate * dBiases[j]\n",
    "            \n",
    "            if verbose and epoch % 10 == 0:\n",
    "                predictions = self.predict(X)\n",
    "                accuracy = np.mean(np.all(predictions == y, axis=1))\n",
    "                print(f\"Epoch {epoch}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward_propagation(X)\n",
    "        return (output >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Multi-Label Binarizer from Scratch, One-Hot encoding\n",
    "class CustomMultiLabelBinarizer:\n",
    "    def __init__(self):\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, y):\n",
    "        unique_labels = set()\n",
    "        for labels in y:\n",
    "            # Handle both list/tuple and string inputs\n",
    "            if isinstance(labels, str):\n",
    "                unique_labels.add(labels)\n",
    "            else:\n",
    "                unique_labels.update(labels)\n",
    "        \n",
    "        # Sort labels\n",
    "        self.classes_ = sorted(list(unique_labels))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        if self.classes_ is None:\n",
    "            raise ValueError(\"Call fit before transform\")\n",
    "        \n",
    "        # Initialize binary matrix\n",
    "        n_samples = len(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        binary_matrix = [[0] * n_classes for _ in range(n_samples)]\n",
    "        \n",
    "        # Create label to index mapping\n",
    "        label_to_idx = {label: idx for idx, label in enumerate(self.classes_)}\n",
    "        \n",
    "        # Fill binary matrix\n",
    "        for i, labels in enumerate(y):\n",
    "            if isinstance(labels, str):\n",
    "                labels = [labels]\n",
    "            for label in labels:\n",
    "                if label in label_to_idx:\n",
    "                    binary_matrix[i][label_to_idx[label]] = 1\n",
    "                    \n",
    "        return binary_matrix\n",
    "    \n",
    "    def fit_transform(self, y):\n",
    "        return self.fit(y).transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vecotrizer Implementation\n",
    "class SimpleCountVectorizer:\n",
    "    def __init__(self, max_features=1000):\n",
    "        self.max_features = max_features\n",
    "        self.vocabulary_ = {}\n",
    "        self.vocab_size = 0\n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "        return tokens\n",
    "    \n",
    "    def fit(self, documents):\n",
    "        word_freq = defaultdict(int)\n",
    "        for doc in documents:\n",
    "            tokens = self._tokenize(doc)\n",
    "            for token in tokens:\n",
    "                word_freq[token] += 1\n",
    "        \n",
    "        sorted_words = sorted(word_freq.items(), key=lambda x: (-x[1], x[0]))\n",
    "        self.vocabulary_ = {word: idx for idx, (word, _) in enumerate(sorted_words[:self.max_features])}\n",
    "        self.vocab_size = len(self.vocabulary_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, documents):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        \n",
    "        for doc_idx, doc in enumerate(documents):\n",
    "            tokens = self._tokenize(doc)\n",
    "            doc_word_counts = defaultdict(int)\n",
    "            \n",
    "            for token in tokens:\n",
    "                if token in self.vocabulary_:\n",
    "                    doc_word_counts[token] += 1\n",
    "                    \n",
    "            for token, count in doc_word_counts.items():\n",
    "                vocab_idx = self.vocabulary_[token]\n",
    "                rows.append(doc_idx)\n",
    "                cols.append(vocab_idx)\n",
    "                data.append(count)\n",
    "        \n",
    "        # Create sparse matrix\n",
    "        return csr_matrix((data, (rows, cols)), \n",
    "                        shape=(len(documents), self.vocab_size))\n",
    "    \n",
    "    def fit_transform(self, documents):\n",
    "        return self.fit(documents).transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model, and testing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Accuracy: 0.0000\n",
      "Epoch 10, Accuracy: 0.5182\n",
      "Epoch 20, Accuracy: 0.7606\n",
      "Epoch 30, Accuracy: 0.8252\n",
      "Epoch 40, Accuracy: 0.8555\n",
      "Epoch 50, Accuracy: 0.8699\n",
      "Epoch 60, Accuracy: 0.8821\n",
      "Epoch 70, Accuracy: 0.8920\n",
      "Epoch 80, Accuracy: 0.9036\n",
      "Epoch 90, Accuracy: 0.9095\n",
      "Epoch 100, Accuracy: 0.9178\n",
      "Epoch 110, Accuracy: 0.9235\n",
      "Epoch 120, Accuracy: 0.9270\n",
      "Epoch 130, Accuracy: 0.9316\n",
      "Epoch 140, Accuracy: 0.9356\n",
      "Epoch 150, Accuracy: 0.9410\n",
      "Epoch 160, Accuracy: 0.9455\n",
      "Epoch 170, Accuracy: 0.9502\n",
      "Epoch 180, Accuracy: 0.9508\n",
      "Epoch 190, Accuracy: 0.9521\n",
      "Epoch 200, Accuracy: 0.9553\n",
      "Epoch 210, Accuracy: 0.9579\n",
      "Epoch 220, Accuracy: 0.9590\n",
      "Epoch 230, Accuracy: 0.9612\n",
      "Epoch 240, Accuracy: 0.9628\n",
      "\n",
      "Neural Network Accuracy: 0.8207612456747405\n",
      "\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.83      0.79      0.81       246\n",
      "     Entertainment       0.93      0.90      0.92       284\n",
      "     International       0.78      0.74      0.76       299\n",
      "Science-Technology       0.85      0.84      0.84       311\n",
      "            Sports       0.96      0.95      0.96       305\n",
      "\n",
      "         micro avg       0.87      0.85      0.86      1445\n",
      "         macro avg       0.87      0.84      0.86      1445\n",
      "      weighted avg       0.87      0.85      0.86      1445\n",
      "       samples avg       0.83      0.85      0.84      1445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "vectorizer = SimpleCountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Prepare labels\n",
    "mlb = CustomMultiLabelBinarizer()\n",
    "y = np.array(mlb.fit_transform([[label] for label in df['gold_label']]))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to dense arrays\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Initialize and train the network\n",
    "input_size = X_train_dense.shape[1]\n",
    "hidden_sizes = [256, 128]\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "nn = MultiLabelNeuralNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    output_size=output_size,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "# Train\n",
    "nn.fit(X_train_dense, y_train, epochs=250, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = nn.predict(X_test_dense)\n",
    "print(\"\\nNeural Network Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: It gives an accuracy of 87.5% on the test dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on Externally Source Data *(to mimic the real-world scenario)*\n",
    "\n",
    "- The test is on `DAWN` dataset, which follows a similar distribution as our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new dataset: 0.8803418803418803\n",
      "\n",
      "Classification Report on new dataset:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.98      0.83      0.90        63\n",
      "     Entertainment       0.00      0.00      0.00         3\n",
      "     International       0.90      0.97      0.93       149\n",
      "Science-Technology       0.88      0.74      0.80        19\n",
      "            Sports       0.00      0.00      0.00         0\n",
      "\n",
      "         micro avg       0.89      0.90      0.90       234\n",
      "         macro avg       0.55      0.51      0.53       234\n",
      "      weighted avg       0.91      0.90      0.90       234\n",
      "       samples avg       0.89      0.90      0.89       234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "new_df = pd.read_csv('../data/dawn_dataset_c.csv')\n",
    "\n",
    "# Preprocess the content\n",
    "new_df['content'] = new_df['content'].apply(lambda x: clean_content(x, urdu_stopwords))\n",
    "\n",
    "# Transform the new data using the existing vectorizer\n",
    "X_new = vectorizer.transform(new_df['content'])\n",
    "\n",
    "# Convert to dense array\n",
    "X_new_dense = X_new.toarray()\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_new = nn.predict(X_new_dense)\n",
    "\n",
    "# If the new dataset has labels, evaluate the performance\n",
    "if 'gold_label' in new_df.columns:\n",
    "    # Prepare labels\n",
    "    new_df['gold_label'] = new_df['gold_label'].fillna('')\n",
    "    new_df['gold_label'] = new_df['gold_label'].str.split(',')\n",
    "    new_df['gold_label'] = new_df['gold_label'].apply(lambda x: [label.strip() for label in x if label.strip()])\n",
    "    y_new = mlb.transform(new_df['gold_label'])\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(\"Accuracy on new dataset:\", accuracy_score(y_new, y_pred_new))\n",
    "    print(\"\\nClassification Report on new dataset:\")\n",
    "    print(classification_report(y_new, y_pred_new, target_names=mlb.classes_))\n",
    "else:\n",
    "    # Convert predictions to labels\n",
    "    predicted_labels = mlb.inverse_transform(y_pred_new)\n",
    "\n",
    "    # Add predictions to the dataframe\n",
    "    new_df['predicted_labels'] = [';'.join(labels) for labels in predicted_labels]\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    new_df.to_csv('./data/dawn_dataset_predictions.csv', index=False)\n",
    "\n",
    "    # Display the predictions\n",
    "    print(new_df[['content', 'predicted_labels']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The test is on `BBC` dataset, which follows a different distribution as our training set with long articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new dataset: 0.6846689895470384\n",
      "\n",
      "Classification Report on new dataset:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Business       0.90      0.64      0.75       222\n",
      "     Entertainment       0.76      0.94      0.84       240\n",
      "     International       0.68      0.84      0.75       208\n",
      "Science-Technology       0.53      0.67      0.60       239\n",
      "            Sports       0.93      0.96      0.95       239\n",
      "\n",
      "         micro avg       0.74      0.81      0.78      1148\n",
      "         macro avg       0.76      0.81      0.78      1148\n",
      "      weighted avg       0.76      0.81      0.78      1148\n",
      "       samples avg       0.75      0.81      0.77      1148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "new_df = pd.read_csv('../data/bbc_dataset_c.csv')\n",
    "\n",
    "# Preprocess the content\n",
    "new_df['content'] = new_df['content'].apply(lambda x: clean_content(x, urdu_stopwords))\n",
    "\n",
    "# Transform the new data using the existing vectorizer\n",
    "X_new = vectorizer.transform(new_df['content'])\n",
    "\n",
    "# Convert to dense array\n",
    "X_new_dense = X_new.toarray()\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_new = nn.predict(X_new_dense)\n",
    "\n",
    "# If the new dataset has labels, evaluate the performance\n",
    "if 'gold_label' in new_df.columns:\n",
    "    # Prepare labels\n",
    "    new_df['gold_label'] = new_df['gold_label'].fillna('')\n",
    "    new_df['gold_label'] = new_df['gold_label'].str.split(',')\n",
    "    new_df['gold_label'] = new_df['gold_label'].apply(lambda x: [label.strip() for label in x if label.strip()])\n",
    "    y_new = mlb.transform(new_df['gold_label'])\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(\"Accuracy on new dataset:\", accuracy_score(y_new, y_pred_new))\n",
    "    print(\"\\nClassification Report on new dataset:\")\n",
    "    print(classification_report(y_new, y_pred_new, target_names=mlb.classes_))\n",
    "else:\n",
    "    # Convert predictions to labels\n",
    "    predicted_labels = mlb.inverse_transform(y_pred_new)\n",
    "\n",
    "    # Add predictions to the dataframe\n",
    "    new_df['predicted_labels'] = [';'.join(labels) for labels in predicted_labels]\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    new_df.to_csv('./data/dawn_dataset_predictions.csv', index=False)\n",
    "\n",
    "    # Display the predictions\n",
    "    print(new_df[['content', 'predicted_labels']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Thank you for bearing through this end*.<br>\n",
    "For testing your dataset, please change one of the above *External Test Datasets* to your dataset and run the code. The notebook will automatically test the model on the new dataset. Please ensure that the file direcotry is correct and the dataset is in the same format as the training and testing datasets. See *Testing your dataset* section in the report for more details.\n",
    "###### (c) Habibi Group, Fall 2024"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
